import streamlit as st
from datetime import datetime
import csv
from pathlib import Path
from dotenv import load_dotenv
import uuid
import json
import streamlit.components.v1 as components
from PIL import Image
import pickle
import math

# LangChain ê´€ë ¨ import
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain.storage import LocalFileStore, EncoderBackedStore
from langchain.retrievers import ParentDocumentRetriever
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.cache import SQLiteCache
from langchain_core.globals import set_llm_cache

# ============================================================================
# í˜ì´ì§€ ì„¤ì • (ê°€ì¥ ë¨¼ì €!)
# ============================================================================
st.set_page_config(
    page_title="í™ìµëŒ€ RAG QnA ì±—ë´‡",
    page_icon="ğŸ’¬",
    layout="wide"
)

# ============================================================================
# ì „ì—­ ì„¤ì •
# ============================================================================
BASE_DIR = Path(__file__).parent
CHROMA_DIR = BASE_DIR / "build_vector_db" / "chroma_db"
DOCSTORE_DIR = BASE_DIR / "build_vector_db" / "docstore"
COLLECTION_NAME = "hongik_data"

# LLM ìºì‹œ ì„¤ì •
LLM_CACHE_DIR = BASE_DIR / "build_vector_db" / "llm_cache"
LLM_CACHE_DIR.mkdir(parents=True, exist_ok=True)
LLM_CACHE_DB = LLM_CACHE_DIR / "llm_cache.db"

#  ìµœì‹ ì„±(rencency) ê°€ì¤‘ì¹˜ ë¦¬ë­í‚¹ íŒŒë¼ë¯¸í„°
# - alphaê°€ í´ìˆ˜ë¡ "ì˜ë¯¸ ìœ ì‚¬ë„"ë¥¼ ë” ì¤‘ì‹œ
# - (1-alpha)ê°€ í´ìˆ˜ë¡ "ìµœê·¼ ë¬¸ì„œ"ë¥¼ ë” ì¤‘ì‹œ
RECENCY_ALPHA = 0.75
RECENCY_DECAY_DAYS = 360

#  assistant(ì±—ë´‡) ì•„ë°”íƒ€
try:
    HONGIK_AVATAR = Image.open("hongik_emblem.png")
except Exception:
    HONGIK_AVATAR = "ğŸ¤–"

#  user(ì§ˆë¬¸ì) ì•„ë°”íƒ€
try:
    USER_AVATAR = Image.open("mascot.png")
except Exception:
    USER_AVATAR = "ğŸ‘¤"


# ============================================================================
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ============================================================================
if "messages" not in st.session_state:
    st.session_state.messages = []

if "feedback_mode" not in st.session_state:
    st.session_state.feedback_mode = {}

if "feedback_ids" not in st.session_state:
    st.session_state.feedback_ids = {}

if "pending_question" not in st.session_state:
    st.session_state.pending_question = None

if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())

if "rag_chain" not in st.session_state:
    st.session_state.rag_chain = None

if "retriever" not in st.session_state:
    st.session_state.retriever = None

if "selected_category" not in st.session_state:
    st.session_state.selected_category = "ì „ì²´"

if "last_similarity" not in st.session_state:
    st.session_state.last_similarity = {}

# ============================================================================
# ì¹´í…Œê³ ë¦¬
# ============================================================================
CATEGORIES = {
    "ì „ì²´": None,
    "ëŒ€í•™ê³µì§€": "ëŒ€í•™ê³µì§€",
    "í•™ê³¼ê³µì§€": "í•™ê³¼ê³µì§€",
    "êµê³¼ëª©/ìˆ˜ê°•": "êµê³¼ëª©/ìˆ˜ê°•"
}

# ============================================================================
# ë¹ ë¥¸ ì§ˆë¬¸
# ============================================================================
QUICK_QUESTIONS = {
    "ì „ì²´": [
        "ìµœê·¼ ê³µì§€ì‚¬í•­ ì•Œë ¤ì¤˜",
        "ì´ë²ˆ í•™ê¸° ì£¼ìš” ì¼ì •ì€?",
        "ì¥í•™ê¸ˆ ì •ë³´ ì•Œë ¤ì¤˜"
    ],
    "ëŒ€í•™ê³µì§€": [
        "í•™êµ ì „ì²´ ê³µì§€ì‚¬í•­ ìµœê·¼ê±° ë³´ì—¬ì¤˜",
        "ëŒ€í•™ì› ì…í•™ ì •ë³´ ì•Œë ¤ì¤˜",
        "í•™ì‚¬ ì¼ì • ì•Œë ¤ì¤˜"
    ],
    "í•™ê³¼ê³µì§€": [
        "ë””ìì¸í•™ë¶€ ê³µì§€ì‚¬í•­ ì•Œë ¤ì¤˜",
        "ê±´ì¶•í•™ë¶€ ìµœê·¼ ì†Œì‹ì€?",
        "ì»´í“¨í„°ê³µí•™ë¶€ ê³µì§€ ë³´ì—¬ì¤˜"
    ],
    "êµê³¼ëª©/ìˆ˜ê°•": [
        "ì´ë²ˆ í•™ê¸° ê°œì„¤ ê³¼ëª© ì•Œë ¤ì¤˜",
        "ìˆ˜ê°•ì‹ ì²­ ì¼ì •ì€?",
        "êµì–‘ ê³¼ëª© ì¶”ì²œí•´ì¤˜"
    ]
}

# ============================================================================
# UI Helper
# ============================================================================

def render_copy_button(content: str, idx: int):
    js_text = json.dumps(content)
    copy_html = f"""
    <html>
    <body>
      <button onclick="copyText_{idx}()"
              style="font-size:0.7rem;padding:3px 10px;
                     border-radius:6px;border:1px solid #ccc;
                     background:#fff;cursor:pointer;">
        ë³µì‚¬
      </button>

      <script>
        const textToCopy_{idx} = {js_text};

        function copyText_{idx}() {{
            if (navigator.clipboard && navigator.clipboard.writeText) {{
                navigator.clipboard.writeText(textToCopy_{idx}).then(() => {{
                    alert("ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤");
                }}).catch(err => {{
                    fallbackCopy_{idx}();
                }});
            }} else {{
                fallbackCopy_{idx}();
            }}
        }}

        function fallbackCopy_{idx}() {{
            const ta = document.createElement("textarea");
            ta.value = textToCopy_{idx};
            document.body.appendChild(ta);
            ta.select();
            document.execCommand("copy");
            document.body.removeChild(ta);
            alert("ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤");
        }}
      </script>
    </body>
    </html>
    """
    components.html(copy_html, height=60, width=120)


def render_sources_box(sources: list):
    if not sources:
        return

    src_html = """
    <div style="
        font-size:0.75rem;
        color:#555;
        margin-top:0.35rem;
        margin-bottom:0.4rem;
        padding:0.4rem 0.6rem;
        background-color:#f5f6fa;
        border-radius:6px;
        border:1px solid #e0e3ec;
    ">
      <div style="font-weight:600; margin-bottom:0.2rem;">ì¶œì²˜</div>
    """
    for s in sources:
        src_html += f"Â· {s}<br>"
    src_html += "</div>"
    st.markdown(src_html, unsafe_allow_html=True)


# ============================================================================
# Scoring (Recency / Similarity)
# ============================================================================

def calculate_recency_weight(date_str: str, decay_days: int = RECENCY_DECAY_DAYS) -> float:
    """
    ë‚ ì§œ ê¸°ë°˜ ìµœì‹ ì„± ê°€ì¤‘ì¹˜ (0.1~1.0)
    - date_str: "YYYY-MM-DD" ë˜ëŠ” "YYYY.MM.DD" ê°€ì •
    """
    try:
        if date_str in ["ìƒì‹œ", "ë‚ ì§œë¯¸ìƒ", None, ""]:
            return 1

        normalized_date = str(date_str).replace(".", "-").strip()
        doc_date = datetime.strptime(normalized_date, "%Y-%m-%d")
        today = datetime.now()
        days_old = (today - doc_date).days

        weight = math.exp(-days_old / decay_days)
        return max(0.1, min(1.0, weight))
    except Exception:
        return 0.5


def _extract_parent_id(metadata: dict):
    if not metadata:
        return None
    for key in ("doc_id", "parent_id", "parent", "document_id"):
        val = metadata.get(key)
        if val:
            return val
    return None


def _score_to_similarity(score):
    try:
        return 1 / (1 + float(score))
    except Exception:
        return 0.5


def get_confidence_level(similarity: float) -> tuple:
    if similarity >= 0.8:
        return "ë§¤ìš° ë†’ìŒ â­â­â­", "ğŸŸ¢", "success"
    elif similarity >= 0.6:
        return "ë†’ìŒ â­â­", "ğŸŸ¡", "info"
    elif similarity >= 0.4:
        return "ë³´í†µ â­", "ğŸŸ ", "warning"
    else:
        return "ë‚®ìŒ", "ğŸ”´", "error"


def display_confidence_badge(similarity: float):
    confidence_text, emoji, alert_type = get_confidence_level(similarity)

    if alert_type == "success":
        st.success(f"{emoji} **ë‹µë³€ ì‹ ë¢°ë„: {confidence_text}** ({similarity:.1%})")
    elif alert_type == "info":
        st.info(f"{emoji} **ë‹µë³€ ì‹ ë¢°ë„: {confidence_text}** ({similarity:.1%})")
    elif alert_type == "warning":
        st.warning(f"{emoji} **ë‹µë³€ ì‹ ë¢°ë„: {confidence_text}** ({similarity:.1%})")
    else:
        st.error(f"{emoji} **ë‹µë³€ ì‹ ë¢°ë„: {confidence_text}** ({similarity:.1%})")
        st.caption("ğŸ’¡ ê²€ìƒ‰ ê²°ê³¼ì™€ ì§ˆë¬¸ì˜ ìœ ì‚¬ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ í•´ë³´ì„¸ìš”.")


# ============================================================================
# Feedback
# ============================================================================

def save_feedback(feedback_data, is_update=False, feedback_id=None):
    """í”¼ë“œë°±ì„ CSV íŒŒì¼ë¡œ ì €ì¥í•˜ê³  feedback_idë¥¼ ë°˜í™˜"""
    feedback_dir = Path("data/feedbacks")
    feedback_dir.mkdir(parents=True, exist_ok=True)

    today = datetime.now().strftime("%Y%m%d")
    feedback_file = feedback_dir / f"feedback_{today}.csv"

    fieldnames = [
        "feedback_id", "timestamp", "question", "answer",
        "feedback_type", "feedback_text", "edit_count", "updated_at"
    ]

    if is_update and feedback_id:
        feedbacks = []
        if feedback_file.exists():
            with open(feedback_file, "r", encoding="utf-8", newline="") as f:
                reader = csv.DictReader(f)
                for row in reader:
                    if row.get("feedback_id") == feedback_id:
                        row["feedback_text"] = feedback_data.get("feedback_text", "")
                        row["updated_at"] = datetime.now().isoformat()
                        row["edit_count"] = str(int(row.get("edit_count", 0)) + 1)
                    feedbacks.append(row)

        with open(feedback_file, "w", encoding="utf-8", newline="") as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(feedbacks)

        return feedback_id

    new_id = str(uuid.uuid4())
    row = {
        "feedback_id": new_id,
        "timestamp": feedback_data.get("timestamp", datetime.now().isoformat()),
        "question": feedback_data.get("question", ""),
        "answer": feedback_data.get("answer", ""),
        "feedback_type": feedback_data.get("feedback_type", ""),
        "feedback_text": feedback_data.get("feedback_text", ""),
        "edit_count": 0,
        "updated_at": ""
    }

    file_exists = feedback_file.exists()
    with open(feedback_file, "a", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        if not file_exists:
            writer.writeheader()
        writer.writerow(row)

    return new_id


# ============================================================================
# RAG Init
# ============================================================================

@st.cache_resource
def initialize_rag_system():
    """ParentDocumentRetriever ê¸°ë°˜ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    try:
        load_dotenv()
        set_llm_cache(SQLiteCache(database_path=str(LLM_CACHE_DB)))

        if not CHROMA_DIR.exists():
            st.error(f"âŒ ChromaDBë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {CHROMA_DIR}")
            st.info("ğŸ’¡ ë¨¼ì € ë²¡í„°DB êµ¬ì¶• ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”!")
            return None, None

        if not DOCSTORE_DIR.exists():
            st.error(f"âŒ Docstoreë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {DOCSTORE_DIR}")
            return None, None

        embeddings = OpenAIEmbeddings(model="text-embedding-3-large")

        vectorstore = Chroma(
            collection_name=COLLECTION_NAME,
            embedding_function=embeddings,
            persist_directory=str(CHROMA_DIR)
        )

        fs = LocalFileStore(str(DOCSTORE_DIR))
        docstore = EncoderBackedStore(
            store=fs,
            key_encoder=lambda x: x,
            value_serializer=pickle.dumps,
            value_deserializer=pickle.loads
        )

        child_splitter = RecursiveCharacterTextSplitter(
            chunk_size=400,
            chunk_overlap=50,
            separators=["\n\n", "\n", " ", ""]
        )

        retriever = ParentDocumentRetriever(
            vectorstore=vectorstore,
            docstore=docstore,
            child_splitter=child_splitter,
            parent_splitter=None
        )

        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0, streaming=True)

        prompt = ChatPromptTemplate.from_messages([
            ('system', '''ë‹¹ì‹ ì€ í™ìµëŒ€í•™êµ í•™ì‚¬ ì •ë³´ ì•ˆë‚´ ì±—ë´‡ì…ë‹ˆë‹¤.

ì—­í• :
- í•™ìƒë“¤ì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤
- ì œê³µëœ ì°¸ê³  ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤
- ê²€ìƒ‰ ê²°ê³¼ì— URLì´ ìˆë‹¤ë©´ ë°˜ë“œì‹œ í¬í•¨í•˜ì—¬ ì•ˆë‚´í•©ë‹ˆë‹¤

ì°¸ê³  ë¬¸ì„œ í™œìš© ë°©ë²•:
- ê° ë¬¸ì„œì—ëŠ” ì œëª©, ë‚ ì§œ, ë¶„ë¥˜, í•™ê³¼, URL, ë‚´ìš©ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤
- ì—¬ëŸ¬ ë¬¸ì„œê°€ ìˆì„ ë•ŒëŠ” ë‚ ì§œê°€ ìµœê·¼ì¸ ì •ë³´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì•ˆë‚´í•˜ì„¸ìš”

ë‹µë³€ ê·œì¹™:
1. ì°¸ê³  ë¬¸ì„œì˜ ì œëª©ê³¼ ë‚ ì§œë¥¼ ì–¸ê¸‰í•˜ì—¬ ì‹ ë¢°ì„±ì„ ë†’ì…ë‹ˆë‹¤
2. ì—¬ëŸ¬ ê²°ê³¼ê°€ ìˆì„ ê²½ìš° ê°ê°ì„ êµ¬ë¶„í•˜ì—¬ ê°„ëµíˆ ìš”ì•½í•©ë‹ˆë‹¤
3. URLì€ "ìì„¸í•œ ë‚´ìš©: [URL]" í˜•ì‹ìœ¼ë¡œ ë°˜ë“œì‹œ ì•ˆë‚´í•©ë‹ˆë‹¤
4. ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ê´€ë ¨ ì •ë³´ê°€ ì—†ìœ¼ë©´ ì†”ì§í•˜ê²Œ ì•Œë ¤ì¤ë‹ˆë‹¤
5. ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ë§¥ë½ì— ë§ëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤
'''),
            MessagesPlaceholder(variable_name="history"),
            ('human', 'ì§ˆë¬¸: {question}\n\nì°¸ê³  ë¬¸ì„œ:\n{context}'),
        ])

        chain = prompt | llm | StrOutputParser()
        return chain, retriever

    except Exception as e:
        st.error(f"RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
        return None, None


# ============================================================================
# Retrieval + Recency Re-rank
# ============================================================================

def get_filtered_documents(retriever, query: str, category_filter: str = None, k: int = 50):
    """
    ì¹´í…Œê³ ë¦¬ í•„í„°ë¥¼ Chroma ê²€ìƒ‰ì— ì§ì ‘ ì ìš©
    child ê²€ìƒ‰(score í¬í•¨) â†’ parent ë³µì›
    ì˜ë¯¸ìœ ì‚¬ë„ + ìµœì‹ ì„± ê°€ì¤‘ì¹˜ë¡œ ë¦¬ë­í¬
    ë°˜í™˜: (docs, avg_semantic_similarity)
    """
    try:
        vectorstore = retriever.vectorstore
        docstore = retriever.docstore

        chroma_filter = None
        if category_filter and category_filter != "ì „ì²´":
            chroma_filter = {"notice_type": category_filter}

        # 1) child ê²€ìƒ‰ (score í¬í•¨)
        child_results = vectorstore.similarity_search_with_score(
            query,
            k=k * 5,                 # ë¦¬ë­í¬/ì¤‘ë³µ ì œê±° ê³ ë ¤ ë„‰ë„‰íˆ
            filter=chroma_filter
        )
        if not child_results:
            return [], 0.0

        # 2) parentë³„ best semantic similarity ìˆ˜ì§‘ + parent id ìˆœì„œ
        parent_id_to_best_sim = {}
        parent_ids = []
        for child_doc, score in child_results:
            pid = _extract_parent_id(child_doc.metadata)
            if not pid:
                # parent idê°€ ì•„ì˜ˆ ì—†ë‹¤ë©´ childë¥¼ parent ì·¨ê¸‰ fallback
                pid = f"__child__:{hash(child_doc.page_content)}"

            sim = _score_to_similarity(score)

            if pid not in parent_id_to_best_sim:
                parent_id_to_best_sim[pid] = sim
                parent_ids.append(pid)
            else:
                parent_id_to_best_sim[pid] = max(parent_id_to_best_sim[pid], sim)

            if len(parent_ids) >= (k * 3):
                break

        # 3) parent ë¡œë“œ
        loaded = docstore.mget(parent_ids)
        parent_docs = []
        parent_meta = []  # (doc, semantic_sim)
        for pid, doc in zip(parent_ids, loaded):
            if doc is None:
                continue
            parent_docs.append(doc)
            parent_meta.append((doc, parent_id_to_best_sim.get(pid, 0.5)))

        # docstore missê°€ ë§ìœ¼ë©´ child fallback
        if not parent_docs:
            fallback_docs = [d for d, _ in child_results[:k]]
            avg_sim = sum([_score_to_similarity(s) for _, s in child_results[:k]]) / max(1, len(fallback_docs))
            return fallback_docs, avg_sim

        # 4) ìµœì‹ ì„± ê°€ì¤‘ì¹˜ë¡œ ë¦¬ë­í¬
        scored = []
        for doc, sem_sim in parent_meta:
            md = doc.metadata or {}
            rec = calculate_recency_weight(md.get("date"), decay_days=RECENCY_DECAY_DAYS)
            final_score = (RECENCY_ALPHA * sem_sim) + ((1 - RECENCY_ALPHA) * rec)
            scored.append((final_score, sem_sim, rec, doc))

        scored.sort(key=lambda x: x[0], reverse=True)
        top = scored[:k]
        top_docs = [d for _, _, _, d in top]

        # ì‹ ë¢°ë„ ë°°ì§€ëŠ” "ì˜ë¯¸ ìœ ì‚¬ë„" í‰ê· ìœ¼ë¡œ ìœ ì§€ (ìµœì‹ ì„±ì€ ì •ë ¬ì—ë§Œ ë°˜ì˜)
        avg_semantic_similarity = sum([sem for _, sem, _, _ in top]) / max(1, len(top))

        # (ë””ë²„ê·¸/í™•ì¥ìš©) ë¦¬ë­í¬ ì ìˆ˜ë„ ê°™ì´ ë³´ê´€ ê°€ëŠ¥
        st.session_state.last_rerank_debug = [
            {
                "title": (doc.metadata or {}).get("title", ""),
                "date": (doc.metadata or {}).get("date", ""),
                "semantic": sem,
                "recency": rec,
                "final": fin
            }
            for fin, sem, rec, doc in top
        ]

        return top_docs, avg_semantic_similarity

    except Exception as e:
        st.error(f"ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return [], 0.0


def get_answer_stream(chain, retriever, query: str, history: list, category_filter: str = None):
    """ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ ë‹µë³€ ìƒì„± (ìµœì‹ ì„± ë¦¬ë­í¬ ë°˜ì˜)"""
    context_docs, avg_similarity = get_filtered_documents(retriever, query, category_filter, k=20)

    if not context_docs:
        yield "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”."
        return

    context_parts = []
    for idx, doc in enumerate(context_docs, 1):
        metadata = doc.metadata or {}
        context_part = f"""[ë¬¸ì„œ {idx}]
ì œëª©: {metadata.get('title', 'ì œëª© ì—†ìŒ')}
ë‚ ì§œ: {metadata.get('date', 'ë‚ ì§œ ì—†ìŒ')}
ë¶„ë¥˜: {metadata.get('notice_type', 'ë¯¸ë¶„ë¥˜')}
í•™ê³¼: {metadata.get('department', 'í•´ë‹¹ì—†ìŒ')}
URL: {metadata.get('url', 'URL ì—†ìŒ')}

ë‚´ìš©:
{doc.page_content}
"""
        context_parts.append(context_part)

    context = '\n\n---\n\n'.join(context_parts)

    st.session_state.last_similarity = {
        "score": avg_similarity,
        "docs": context_docs
    }

    for chunk in chain.stream({
        "question": query,
        "context": context,
        "history": history
    }):
        yield chunk


# ============================================================================
# Main interaction
# ============================================================================

def process_question(prompt):
    st.session_state.messages.append({"role": "user", "content": prompt})

    try:
        if st.session_state.rag_chain is None or st.session_state.retriever is None:
            chain, retriever = initialize_rag_system()
            st.session_state.rag_chain = chain
            st.session_state.retriever = retriever

        if st.session_state.rag_chain is None:
            raise Exception("RAG ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # ìµœê·¼ 5ê°œ íˆìŠ¤í† ë¦¬
        history = []
        for msg in st.session_state.messages[-6:-1]:
            role = msg["role"]
            content = msg["content"]
            if role == "user":
                history.append(("user", content))
            else:
                history.append(("assistant", content))

        category_filter = st.session_state.get("selected_category", "ì „ì²´")
        if category_filter == "ì „ì²´":
            category_filter = None

        response_placeholder = st.empty()
        full_response = ""

        for chunk in get_answer_stream(
            st.session_state.rag_chain,
            st.session_state.retriever,
            prompt,
            history,
            category_filter
        ):
            full_response += chunk
            response_placeholder.markdown(full_response + "â–Œ")

        response_placeholder.markdown(full_response)

        similarity_score = st.session_state.last_similarity.get("score", 0.0)
        retrieved_docs = st.session_state.last_similarity.get("docs", [])

        st.session_state.messages.append({
            "role": "assistant",
            "content": full_response,
            "similarity": similarity_score,
            "docs": retrieved_docs
        })

    except Exception as e:
        error_message = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        st.session_state.messages.append({
            "role": "assistant",
            "content": error_message,
            "similarity": None,
            "docs": []
        })


# ============================================================================
# UI
# ============================================================================

with st.sidebar:
    st.title("ğŸ“ í™ìµëŒ€ QnA ì±—ë´‡")
    st.markdown("---")

    st.subheader("ğŸ·ï¸ ì¹´í…Œê³ ë¦¬ í•„í„°")
    selected = st.radio(
        "ê²€ìƒ‰ ë²”ìœ„ë¥¼ ì„ íƒí•˜ì„¸ìš”",
        options=list(CATEGORIES.keys()),
        index=list(CATEGORIES.keys()).index(st.session_state.selected_category),
        key="category_radio"
    )
    if selected != st.session_state.selected_category:
        st.session_state.selected_category = selected
        st.rerun()

    st.markdown("---")

    st.subheader("âš¡ ë¹ ë¥¸ ì§ˆë¬¸")
    quick_qs = QUICK_QUESTIONS.get(st.session_state.selected_category, [])
    for q in quick_qs:
        if st.button(q, key=f"quick_{q}", use_container_width=True):
            st.session_state.pending_question = q
            st.rerun()

    st.markdown("---")

    if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”", use_container_width=True):
        st.session_state.messages = []
        st.session_state.feedback_mode = {}
        st.session_state.feedback_ids = {}
        st.session_state.last_similarity = {}
        st.session_state.pop("last_rerank_debug", None)
        st.rerun()

    st.markdown("---")
    st.caption(f"ì„¸ì…˜ ID: {st.session_state.session_id[:8]}...")
    st.caption("ğŸ“Š RAG: ParentDocumentRetriever + Recency Re-rank")


st.title("ğŸ’¬ í™ìµëŒ€í•™êµ í•™ì‚¬ì •ë³´ ì±—ë´‡")
st.markdown(f"**í˜„ì¬ ì¹´í…Œê³ ë¦¬**: {st.session_state.selected_category}")
st.markdown("---")

# ëŒ€í™” ë‚´ì—­ í‘œì‹œ
for idx, message in enumerate(st.session_state.messages):
    role = message["role"]

    # ì•„ë°”íƒ€ ì ìš©: assistantëŠ” HONGIK_AVATAR, userëŠ” USER_AVATAR
    if role == "assistant":
        chat_ctx = st.chat_message("assistant", avatar=HONGIK_AVATAR)
    elif role == "user":
        chat_ctx = st.chat_message("user", avatar=USER_AVATAR)
    else:
        chat_ctx = st.chat_message(role)

    with chat_ctx:
        st.markdown(message["content"])
        
        # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ì—ë§Œ ë²„íŠ¼ í‘œì‹œ
        if role == "assistant":
            # ì‹ ë¢°ë„ í‘œì‹œ
            similarity = message.get("similarity")
            if similarity is not None:
                display_confidence_badge(similarity)
            
            
            docs = message.get("docs", [])
            if docs:
                sources = []
                for doc in docs[:3]:
                    md = doc.metadata or {}
                    title = md.get("title", "ì œëª© ì—†ìŒ")
                    url = md.get("url", "")
                    date = md.get("date", "")
                    notice_type = md.get("notice_type", "")

                    source_text = f"{title}"
                    if date:
                        source_text += f" ({date})"
                    if notice_type:
                        source_text += f" [{notice_type}]"
                    if url:
                        source_text += f" - {url}"
                    sources.append(source_text)

                render_sources_box(sources)
            
            
            
            
            if idx not in st.session_state.feedback_mode:
                # ì™¼ìª½ ì—¬ë°±, ğŸ‘, ğŸ‘, ë³µì‚¬, ì˜¤ë¥¸ìª½ ì—¬ë°±
                spacer_l, col1, col2, col3, spacer_r = st.columns(
                    [0.1, 0.3, 0.3, 0.3, 4]
                )
                with col1:
                    if st.button("ğŸ‘", key=f"like_{idx}"):
                        st.session_state.feedback_mode[idx] = {
                            "type": "satisfied",
                            "text": "",
                            "submitted": False
                        }
                        st.rerun()
                with col2:
                    if st.button("ğŸ‘", key=f"dislike_{idx}"):
                        st.session_state.feedback_mode[idx] = {
                            "type": "unsatisfied",
                            "text": "",
                            "submitted": False
                        }
                        st.rerun()
                with col3:
                    render_copy_button(message["content"], idx)
            else:
                feedback_info = st.session_state.feedback_mode[idx]
                feedback_type = feedback_info["type"]
                
                if feedback_info["submitted"]:
                    st.success("âœ… í”¼ë“œë°±ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤! ğŸ™")
                    st.info(
                        f"**{'ë§Œì¡±' if feedback_type == 'satisfied' else 'ë¶ˆë§Œì¡±'}** ì„ íƒ\n\n"
                        f"**ì˜ê²¬:** {feedback_info['text'] if feedback_info['text'] else '(ì—†ìŒ)'}"
                    )
                    
                    spacer_l, col1, col2, col3, spacer_r = st.columns(
                        [0.1, 0.5, 0.5, 0.4, 5]
                    )
                    with col1:
                        if st.button("âœï¸ ìˆ˜ì •", key=f"edit_{idx}"):
                            st.session_state.feedback_mode[idx]["submitted"] = False
                            st.rerun()
                    with col2:
                        if st.button("ğŸ—‘ï¸ ì‚­ì œ", key=f"delete_{idx}"):
                            del st.session_state.feedback_mode[idx]
                            if idx in st.session_state.feedback_ids:
                                del st.session_state.feedback_ids[idx]
                            st.rerun()
                    with col3:
                        render_copy_button(message["content"], idx)
                else:
                    feedback_text = st.text_area(
                        f"{'ë§Œì¡±í•˜ì‹  ì ' if feedback_type == 'satisfied' else 'ë¶ˆë§Œì¡±í•˜ì‹  ì '}ì„ ìì„¸íˆ ì•Œë ¤ì£¼ì„¸ìš” (ì„ íƒì‚¬í•­):",
                        value=feedback_info["text"],
                        key=f"feedback_text_{idx}",
                        height=100
                    )
                    
                    spacer_l, col1, col2, col3, spacer_r = st.columns(
                        [0.1, 0.5, 0.5, 0.4, 5]
                    )
                    with col1:
                        if st.button("âœ… ì™„ë£Œ", key=f"submit_{idx}"):
                            feedback_data = {
                                "timestamp": datetime.now().isoformat(),
                                "question": st.session_state.messages[idx - 1]["content"] if idx > 0 else "",
                                "answer": message["content"],
                                "feedback_type": feedback_type,
                                "feedback_text": feedback_text
                            }
                            
                            is_update = idx in st.session_state.feedback_ids
                            feedback_id = st.session_state.feedback_ids.get(idx)
                            
                            if is_update:
                                save_feedback(
                                    feedback_data,
                                    is_update=True,
                                    feedback_id=feedback_id
                                )
                            else:
                                save_feedback(feedback_data, is_update=False)
                                st.session_state.feedback_ids[idx] = feedback_data.get(
                                    "feedback_id"
                                )
                            
                            st.session_state.feedback_mode[idx]["text"] = feedback_text
                            st.session_state.feedback_mode[idx]["submitted"] = True
                            st.rerun()
                    with col2:
                        if st.button("âŒ ì·¨ì†Œ", key=f"cancel_{idx}"):
                            del st.session_state.feedback_mode[idx]
                            st.rerun()
                    with col3:
                        render_copy_button(message["content"], idx)

            # ì—¬ê¸°ì„œ ì¶œì²˜ ë°•ìŠ¤ ë Œë”ë§ (í•­ìƒ ë²„íŠ¼ ì•„ë˜)
            sources = message.get("sources", [])
            render_sources_box(sources)


if st.session_state.pending_question:
    question = st.session_state.pending_question
    st.session_state.pending_question = None
    process_question(question)
    st.rerun()

if prompt := st.chat_input("ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”..."):
    process_question(prompt)
    st.rerun()

if len(st.session_state.messages) == 0:
    with st.chat_message("assistant", avatar=HONGIK_AVATAR):
        st.markdown("""
        ì•ˆë…•í•˜ì„¸ìš”! í™ìµëŒ€í•™êµ í•™ì‚¬ì •ë³´ ì±—ë´‡ì…ë‹ˆë‹¤. ğŸ“
        
        **ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?**
        - ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ì„¸ìš”
        - ë¹ ë¥¸ ì§ˆë¬¸ ë²„íŠ¼ì„ ëˆŒëŸ¬ë³´ì„¸ìš”
        - ë˜ëŠ” ì§ì ‘ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!

        ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?
        """)
